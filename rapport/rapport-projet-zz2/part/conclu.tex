%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% CONCLUSION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% TODO

Ceci clôture ce rapport de projet qui traite de la comparaison de complexité de deux méthodes utilisées pour la multiplication de matrices via MapReduce. Cette étude a été menée principalement sur un réseau de machines virtuelles, appelé \textit{cluster}, équipé du système d'exploitation Ubuntu et du framework Hadoop pré-installé. Au fil de ce rapport, nous avons présenté la théorie menée par nos tuteurs. Puis nous avons expliqué comment le \textit{namenode} a été configuré lors de sa création. Ceci afin de préparer les tâches MapReduce qui nous avait été demandé de programmer.\par
Notre objectif initial était de programmer en langage Java deux méthodes différentes de multiplication de matrices, celle demandant une seule étape map et reduce (\textit{One Step}) et celle en demandant deux (\textit{Two Steps}). Compte tenu de nos connaissances initiales dans les compétences qui étaient requises pour ce projet (Hadoop, Java, shell, Git, manipulation d'un cluster), cette première tâche a été réalisé en partie, non sans peine. Parmi les obstacles et principaux contretemps, les plus difficiles à résoudre ont concerné les problèmes internes au cluster. Plus de deux mois ont été nécessaires pour rechercher et assembler de nombreuses documentations sur l'ensemble du sujet. Pendant un autre mois, nous ne comprenions pas comment le HDFS fonctionnait, c'est pourquoi nous nous sommes résolus à faire les mesures sur nos ordinateurs personnelles en attendant le fonctionnement du cluster et du système distribué d'Hadoop.\par
D'après nos séries de mesure, bien que limité en ressources disponibles, nous avons su montrer que la courbe de complexité temporelle du job One Step sécurisé était asymptotiquement prépondérante devant celle du job non sécurisé. La pratique a confirmé le niveau de sécurité démontré par la théorie, de sorte qu'à partir d'aucune des valeurs d'une matrice placée en entrée il ne soit possible de connaître la valeur de l'autre matrice ou de celle en sortie. Le choix de grands nombres premiers permet le calcul de matrices comportant des valeurs élevés comme nous l'avons vu en Partie I.\par
Nous avons rapidement constaté une limite durant les tests, alors que nos tuteurs avaient prévus de rentrer des matrices assimilables aux données d'un système \textit{Big Data}, alors que le cluster est limité en disque dur, la taille maximale de matrices pouvant être traitées par le cluster se situe entre 450 et 500 lignes de valeurs. Nous pouvons comparer l'envergure de nos tests avec ceux de \textit{Google Labs}, le rapport des tests de multiplication de matrices publié sur internet rend compte de leur travail sur un cluster comportant 1800 machines constituées de processeurs Xeon (10 à 18 cœurs). Le cloud OpenStack du LIMOS ne nous délivrant pas des ressources comparables et par manque de temps, le nombre de mesures et le temps d'exécution des tâches MapReduce sont donc affectés.\par
Notre avancement dans le projet nous a permis de programmer et optimiser l'algorithme du One Step, cependant de nombreuses autres perspectives sont envisageables:
\begin{itemize}
\item Finir l'algorithme Java de la multiplication de matrices en deux étapes (Two Steps) que nous avons commencé.
\item Effectuer le même travail de mesures sur cette méthode et la méthode sécurisée associée.
\item Comparer les complexités temporelles du One Step et du Two Steps.
\item Implémenter l'approche Collision-Resistant-Secure-Private (CRSP).
\item Rechercher les courbes théoriques se rapprochant le plus des courbes expérimentales.
\end{itemize}